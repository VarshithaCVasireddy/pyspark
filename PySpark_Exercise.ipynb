{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNc1RDDXiKpL9a9a4+erqL2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VarshithaCVasireddy/pyspark/blob/main/PySpark_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This practice is from https://www.machinelearningplus.com/pyspark/pyspark-exercises-101-pyspark-exercises-for-data-analysis/"
      ],
      "metadata": {
        "id": "EW3YKaHmeqNK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQb7R3YwemUU",
        "outputId": "b71151cb-550d-4f82-9321-85daa5255c48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark"
      ],
      "metadata": {
        "id": "91Ugz6cKevme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "3eADbahFewpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"exercise\").getOrCreate()"
      ],
      "metadata": {
        "id": "m44WNE8Ke4tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 2"
      ],
      "metadata": {
        "id": "_BDm0t7-gkAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame([\n",
        "(\"Alice\", 1),\n",
        "(\"Bob\", 2),\n",
        "(\"Charlie\", 3),\n",
        "], [\"Name\", \"Value\"])\n",
        "\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIzE7gwIfAGs",
        "outputId": "5128d53e-77f5-4e9b-93db-e83e1c89174d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+\n",
            "|   Name|Value|\n",
            "+-------+-----+\n",
            "|  Alice|    1|\n",
            "|    Bob|    2|\n",
            "|Charlie|    3|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number\n",
        "\n",
        "window_spec = Window.orderBy(\"Name\")\n",
        "df = df.withColumn(\"index\",row_number().over(window_spec)-1)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCHSD7N0fDST",
        "outputId": "533ae586-18ff-44a6-dae2-caabadbadabf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+-----+\n",
            "|   Name|Value|index|\n",
            "+-------+-----+-----+\n",
            "|  Alice|    1|    0|\n",
            "|    Bob|    2|    1|\n",
            "|Charlie|    3|    2|\n",
            "+-------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 3"
      ],
      "metadata": {
        "id": "pPgze8X1gmHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = [\"a\", \"b\", \"c\", \"d\"]\n",
        "list2 = [1, 2, 3, 4]"
      ],
      "metadata": {
        "id": "Gq-K8YGXgPW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = spark.sparkContext.parallelize(list(zip(list1,list2)))\n",
        "df = rdd.toDF([\"list1\",\"list2\"])"
      ],
      "metadata": {
        "id": "4VcSK0KVi280"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(zip(list1,list2),[\"list1\",\"list2\"])\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xItB-UlhAIp",
        "outputId": "91d68efb-39b6-4ed5-f70c-9a2628b02da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|list1|list2|\n",
            "+-----+-----+\n",
            "|    a|    1|\n",
            "|    b|    2|\n",
            "|    c|    3|\n",
            "|    d|    4|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 4"
      ],
      "metadata": {
        "id": "dNtsSSaLhOCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_A = [1, 2, 3, 4, 5]\n",
        "list_B = [4, 5, 6, 7, 8]"
      ],
      "metadata": {
        "id": "DGxu8JCAhGrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_A = spark.createDataFrame([(x,) for x in list_A ],[\"Value\"])\n",
        "df_B = spark.createDataFrame([(x,) for x in list_B ],[\"Value\"])\n",
        "\n",
        "result = df_A.join(df_B,on = \"Value\",how=\"left_anti\")\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJpH3R1KhwDA",
        "outputId": "df1360f4-5985-4ca8-cf20-2846da02e41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|Value|\n",
            "+-----+\n",
            "|    1|\n",
            "|    2|\n",
            "|    3|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext\n",
        "\n",
        "rdd_A = sc.parallelize(list_A)\n",
        "rdd_B = sc.parallelize(list_B)\n",
        "\n",
        "result_rdd = rdd_A.subtract(rdd_B)\n",
        "\n",
        "result_rdd = result_rdd.collect()\n",
        "print(result_rdd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Srk29uFAiCqf",
        "outputId": "6e51d776-f78d-4f34-84c9-4795d998ed0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 5"
      ],
      "metadata": {
        "id": "Swie2Gbcj6Nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext\n",
        "\n",
        "rdd_A = sc.parallelize(list_A)\n",
        "rdd_B = sc.parallelize(list_B)\n",
        "\n",
        "result_rdd_A = rdd_A.subtract(rdd_B)\n",
        "result_rdd_B = rdd_B.subtract(rdd_A)\n",
        "\n",
        "result_rdd = result_rdd_A.union(result_rdd_B)\n",
        "\n",
        "print(result_rdd.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSqAkG7sj2nL",
        "outputId": "17e0af2c-a948-4135-b3ac-06f400545170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 8, 6, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 6"
      ],
      "metadata": {
        "id": "99876XGClIT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"A\", 10), (\"B\", 20), (\"C\", 30), (\"D\", 40), (\"E\", 50), (\"F\", 15), (\"G\", 28), (\"H\", 54), (\"I\", 41), (\"J\", 86)]\n",
        "df = spark.createDataFrame(data, [\"Name\", \"Age\"])\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENHPIr_Skx0F",
        "outputId": "bbafb0e2-c216-4f17-9381-a4b4e98e92c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+\n",
            "|Name|Age|\n",
            "+----+---+\n",
            "|   A| 10|\n",
            "|   B| 20|\n",
            "|   C| 30|\n",
            "|   D| 40|\n",
            "|   E| 50|\n",
            "|   F| 15|\n",
            "|   G| 28|\n",
            "|   H| 54|\n",
            "|   I| 41|\n",
            "|   J| 86|\n",
            "+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantile = df.approxQuantile(\"Age\",[0.0,0.25,0.5,0.75,1.0],0.01)\n",
        "print(quantile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HFB6DCflOwR",
        "outputId": "7aa3557a-5078-4873-ed2a-43f5bbde0550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10.0, 20.0, 30.0, 50.0, 86.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 7"
      ],
      "metadata": {
        "id": "37YAanY1mHgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "# Sample data\n",
        "data = [\n",
        "Row(name='John', job='Engineer'),\n",
        "Row(name='John', job='Engineer'),\n",
        "Row(name='Mary', job='Scientist'),\n",
        "Row(name='Bob', job='Engineer'),\n",
        "Row(name='Bob', job='Engineer'),\n",
        "Row(name='Bob', job='Scientist'),\n",
        "Row(name='Sam', job='Doctor'),\n",
        "]\n",
        "\n",
        "# create DataFrame\n",
        "df = spark.createDataFrame(data)\n",
        "\n",
        "# show DataFrame\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAUFEaMRl37o",
        "outputId": "55c83947-5f85-497a-b2fc-102b676da104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+\n",
            "|name|      job|\n",
            "+----+---------+\n",
            "|John| Engineer|\n",
            "|John| Engineer|\n",
            "|Mary|Scientist|\n",
            "| Bob| Engineer|\n",
            "| Bob| Engineer|\n",
            "| Bob|Scientist|\n",
            "| Sam|   Doctor|\n",
            "+----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"job\",\"name\").count().orderBy(\"count\",ascending=False).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0Hd4T3gmMK3",
        "outputId": "8eb2d7e6-203f-4121-b74d-8b2725a966b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+-----+\n",
            "|      job|name|count|\n",
            "+---------+----+-----+\n",
            "| Engineer|John|    2|\n",
            "| Engineer| Bob|    2|\n",
            "|Scientist|Mary|    1|\n",
            "|   Doctor| Sam|    1|\n",
            "|Scientist| Bob|    1|\n",
            "+---------+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 8"
      ],
      "metadata": {
        "id": "NoT6QMnsnfnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "# Sample data\n",
        "data = [\n",
        "Row(name='John', job='Engineer'),\n",
        "Row(name='John', job='Engineer'),\n",
        "Row(name='Mary', job='Scientist'),\n",
        "Row(name='Bob', job='Engineer'),\n",
        "Row(name='Bob', job='Engineer'),\n",
        "Row(name='Bob', job='Scientist'),\n",
        "Row(name='Sam', job='Doctor'),\n",
        "]\n",
        "\n",
        "# create DataFrame\n",
        "df = spark.createDataFrame(data)\n",
        "\n",
        "# show DataFrame\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4sfr7LGmfka",
        "outputId": "345b6485-d023-409e-ff47-b5710e8b0bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+\n",
            "|name|      job|\n",
            "+----+---------+\n",
            "|John| Engineer|\n",
            "|John| Engineer|\n",
            "|Mary|Scientist|\n",
            "| Bob| Engineer|\n",
            "| Bob| Engineer|\n",
            "| Bob|Scientist|\n",
            "| Sam|   Doctor|\n",
            "+----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_top_2 = df.groupBy(\"job\",\"name\").count().orderBy(\"count\",ascending=False).limit(2)\n",
        "df_top_2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBrBsQk0njF9",
        "outputId": "73263ad7-acf6-4e7a-8ec3-e5ad73d644f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+-----+\n",
            "|     job|name|count|\n",
            "+--------+----+-----+\n",
            "|Engineer|John|    2|\n",
            "|Engineer| Bob|    2|\n",
            "+--------+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 10"
      ],
      "metadata": {
        "id": "cnS2l-FwoiTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# suppose you have the following DataFrame\n",
        "df = spark.createDataFrame([(1, 2, 3), (4, 5, 6)], [\"col1\", \"col2\", \"col3\"])\n",
        "\n",
        "# old column names\n",
        "old_names = [\"col1\", \"col2\", \"col3\"]\n",
        "\n",
        "# new column names\n",
        "new_names = [\"new_col1\", \"new_col2\", \"new_col3\"]\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuTJRT5AoBcb",
        "outputId": "a4401566-8e4e-4271-9e3e-3e4fbb8f35cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----+\n",
            "|col1|col2|col3|\n",
            "+----+----+----+\n",
            "|   1|   2|   3|\n",
            "|   4|   5|   6|\n",
            "+----+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for old_name, new_name in zip(old_names, new_names):\n",
        "  df = df.withColumnRenamed(old_name, new_name)\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3UpOPUfor6W",
        "outputId": "692f9cc0-6f9b-48b1-d9c4-28f8e779508c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+--------+\n",
            "|new_col1|new_col2|new_col3|\n",
            "+--------+--------+--------+\n",
            "|       1|       2|       3|\n",
            "|       4|       5|       6|\n",
            "+--------+--------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 13"
      ],
      "metadata": {
        "id": "o7VExXZrp-uV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import rand\n",
        "\n",
        "# Generate a DataFrame with a single column \"id\" with 10 rows\n",
        "df = spark.range(10)\n",
        "\n",
        "# Generate a random float between 0 and 1, scale and shift it to get a random integer between 1 and 10\n",
        "df = df.withColumn(\"random\", ((rand(seed=42) * 10) + 1).cast(\"int\"))\n",
        "\n",
        "# Show the DataFrame\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw8-5m7Gp92C",
        "outputId": "4a8b6f95-c1cb-42e9-b339-b228ad64f7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+\n",
            "| id|random|\n",
            "+---+------+\n",
            "|  0|     7|\n",
            "|  1|     6|\n",
            "|  2|     9|\n",
            "|  3|     3|\n",
            "|  4|     7|\n",
            "|  5|     9|\n",
            "|  6|     7|\n",
            "|  7|     3|\n",
            "|  8|     3|\n",
            "|  9|     7|\n",
            "+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df[\"random\"]% 3 == 0).select(\"id\",\"random\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8iIfjVqq58b",
        "outputId": "e661ccec-1781-4fa3-8a5c-58c2a29c3925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+\n",
            "| id|random|\n",
            "+---+------+\n",
            "|  1|     6|\n",
            "|  2|     9|\n",
            "|  3|     3|\n",
            "|  5|     9|\n",
            "|  7|     3|\n",
            "|  8|     3|\n",
            "+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "df.withColumn(\"Multiple of 3\",when(df[\"random\"]% 3 == 0, 1).otherwise(0)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La7QN5--rLZz",
        "outputId": "0b8f611b-f2d0-4c65-d727-06b7d2c6a8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+-------------+\n",
            "| id|random|Multiple of 3|\n",
            "+---+------+-------------+\n",
            "|  0|     7|            0|\n",
            "|  1|     6|            1|\n",
            "|  2|     9|            1|\n",
            "|  3|     3|            1|\n",
            "|  4|     7|            0|\n",
            "|  5|     9|            1|\n",
            "|  6|     7|            0|\n",
            "|  7|     3|            1|\n",
            "|  8|     3|            1|\n",
            "|  9|     7|            0|\n",
            "+---+------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 14"
      ],
      "metadata": {
        "id": "YNXB04Z9sTkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos = [0,4,8,5]\n",
        "\n",
        "# To create Index\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number\n",
        "\n",
        "window = Window.orderBy(\"id\")\n",
        "df = df.withColumn(\"index\", row_number().over(window) -1)\n",
        "\n",
        "df.filter(df[\"index\"].isin(pos)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uzeHzJJr4hY",
        "outputId": "9663f212-05ca-44c9-e380-c78f6e3313a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+-----+\n",
            "| id|random|index|\n",
            "+---+------+-----+\n",
            "|  0|     7|    0|\n",
            "|  4|     7|    4|\n",
            "|  5|     9|    5|\n",
            "|  8|     3|    8|\n",
            "+---+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 15"
      ],
      "metadata": {
        "id": "N_cmbzvXuTpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame for region A\n",
        "df_A = spark.createDataFrame([(\"apple\", 3, 5), (\"banana\", 1, 10), (\"orange\", 2, 8)], [\"Name\", \"Col_1\", \"Col_2\"])\n",
        "df_A.show()\n",
        "\n",
        "# Create DataFrame for region B\n",
        "df_B = spark.createDataFrame([(\"apple\", 3, 5), (\"banana\", 1, 15), (\"grape\", 4, 6)], [\"Name\", \"Col_1\", \"Col_3\"])\n",
        "df_B.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vgpJ5BVs4x1",
        "outputId": "599b66b3-dfb6-4f91-9839-2988dc9f04cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-----+\n",
            "|  Name|Col_1|Col_2|\n",
            "+------+-----+-----+\n",
            "| apple|    3|    5|\n",
            "|banana|    1|   10|\n",
            "|orange|    2|    8|\n",
            "+------+-----+-----+\n",
            "\n",
            "+------+-----+-----+\n",
            "|  Name|Col_1|Col_3|\n",
            "+------+-----+-----+\n",
            "| apple|    3|    5|\n",
            "|banana|    1|   15|\n",
            "| grape|    4|    6|\n",
            "+------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_A.unionAll(df_B).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf4ZktPLuVU_",
        "outputId": "a9cb51cf-86ce-4794-caa4-75e92338f485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-----+\n",
            "|  Name|Col_1|Col_2|\n",
            "+------+-----+-----+\n",
            "| apple|    3|    5|\n",
            "|banana|    1|   10|\n",
            "|orange|    2|    8|\n",
            "| apple|    3|    5|\n",
            "|banana|    1|   15|\n",
            "| grape|    4|    6|\n",
            "+------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 17"
      ],
      "metadata": {
        "id": "FFrJ7DJkuiee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppose you have the following DataFrame\n",
        "data = [(\"john\",), (\"alice\",), (\"bob\",)]\n",
        "df = spark.createDataFrame(data, [\"name\"])\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvL6kXBBuepO",
        "outputId": "01601de7-fb7f-48eb-bd9c-fbb98490b6e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "| name|\n",
            "+-----+\n",
            "| john|\n",
            "|alice|\n",
            "|  bob|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import initcap\n",
        "\n",
        "df.withColumn(\"name\",initcap(\"name\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGDqA0w2vPAe",
        "outputId": "b5bef556-95c1-4091-e2a5-76786c035b69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "| name|\n",
            "+-----+\n",
            "| John|\n",
            "|Alice|\n",
            "|  Bob|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 18"
      ],
      "metadata": {
        "id": "uRYyyPH1xVGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For the sake of example, we'll create a sample DataFrame\n",
        "data = [('James', 34, 55000),\n",
        "('Michael', 30, 70000),\n",
        "('Robert', 37, 60000),\n",
        "('Maria', 29, 80000),\n",
        "('Jen', 32, 65000)]\n",
        "\n",
        "df = spark.createDataFrame(data, [\"name\", \"age\" , \"salary\"])\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhZm0njAw9EG",
        "outputId": "e23298e3-bc2b-40ae-fbc2-8355db8070e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+------+\n",
            "|   name|age|salary|\n",
            "+-------+---+------+\n",
            "|  James| 34| 55000|\n",
            "|Michael| 30| 70000|\n",
            "| Robert| 37| 60000|\n",
            "|  Maria| 29| 80000|\n",
            "|    Jen| 32| 65000|\n",
            "+-------+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.summary().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P0P-_iCxTra",
        "outputId": "08c92a3b-d60e-4764-da53-705fc20c8142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+-----------------+-----------------+\n",
            "|summary|  name|              age|           salary|\n",
            "+-------+------+-----------------+-----------------+\n",
            "|  count|     5|                5|                5|\n",
            "|   mean|  NULL|             32.4|          66000.0|\n",
            "| stddev|  NULL|3.209361307176242|9617.692030835671|\n",
            "|    min| James|               29|            55000|\n",
            "|    25%|  NULL|               30|            60000|\n",
            "|    50%|  NULL|               32|            65000|\n",
            "|    75%|  NULL|               34|            70000|\n",
            "|    max|Robert|               37|            80000|\n",
            "+-------+------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxZ-2OGzxZdq",
        "outputId": "b8c2bb76-1d5d-4cb0-b199-e6df0598993f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+-----------------+-----------------+\n",
            "|summary|  name|              age|           salary|\n",
            "+-------+------+-----------------+-----------------+\n",
            "|  count|     5|                5|                5|\n",
            "|   mean|  NULL|             32.4|          66000.0|\n",
            "| stddev|  NULL|3.209361307176242|9617.692030835671|\n",
            "|    min| James|               29|            55000|\n",
            "|    max|Robert|               37|            80000|\n",
            "+-------+------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 19"
      ],
      "metadata": {
        "id": "52mU_CVJxh3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"john\",), (\"alice\",), (\"bob\",)]\n",
        "df = spark.createDataFrame(data, [\"name\"])\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8VPHZidxcuS",
        "outputId": "2bdbbfa1-c595-495f-b2b2-349e2aab8dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "| name|\n",
            "+-----+\n",
            "| john|\n",
            "|alice|\n",
            "|  bob|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import char_length\n",
        "df = df.withColumn(\"character_present\", char_length(\"name\")).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kglGvKkWxkl_",
        "outputId": "868f17e1-adbc-48d9-9da5-7d5868c9a7b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+\n",
            "| name|character_present|\n",
            "+-----+-----------------+\n",
            "| john|                4|\n",
            "|alice|                5|\n",
            "|  bob|                3|\n",
            "+-----+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 20"
      ],
      "metadata": {
        "id": "N3B3mu6xyFL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.max(\"character_present\").show()"
      ],
      "metadata": {
        "id": "u3szw4kwx7QI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "54670c56-88b6-4da2-be64-549262b87129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'max'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-b4ee99ff5fd0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"character_present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'max'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3CTqih4HICyI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}