{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPI5HFLvVWvmrCmbpaJFaa5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VarshithaCVasireddy/pyspark/blob/main/pyspark_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This practice is from https://www.machinelearningplus.com/pyspark/pyspark-exercises-101-pyspark-exercises-for-data-analysis/"
      ],
      "metadata": {
        "id": "EW3YKaHmeqNK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQb7R3YwemUU",
        "outputId": "842c80df-41de-43e7-f6ee-5fe3fd4ce432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark"
      ],
      "metadata": {
        "id": "91Ugz6cKevme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "3eADbahFewpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"exercise\").getOrCreate()"
      ],
      "metadata": {
        "id": "m44WNE8Ke4tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 2"
      ],
      "metadata": {
        "id": "_BDm0t7-gkAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame([\n",
        "(\"Alice\", 1),\n",
        "(\"Bob\", 2),\n",
        "(\"Charlie\", 3),\n",
        "], [\"Name\", \"Value\"])\n",
        "\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIzE7gwIfAGs",
        "outputId": "5128d53e-77f5-4e9b-93db-e83e1c89174d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+\n",
            "|   Name|Value|\n",
            "+-------+-----+\n",
            "|  Alice|    1|\n",
            "|    Bob|    2|\n",
            "|Charlie|    3|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number\n",
        "\n",
        "window_spec = Window.orderBy(\"Name\")\n",
        "df = df.withColumn(\"index\",row_number().over(window_spec)-1)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCHSD7N0fDST",
        "outputId": "533ae586-18ff-44a6-dae2-caabadbadabf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+-----+\n",
            "|   Name|Value|index|\n",
            "+-------+-----+-----+\n",
            "|  Alice|    1|    0|\n",
            "|    Bob|    2|    1|\n",
            "|Charlie|    3|    2|\n",
            "+-------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 3"
      ],
      "metadata": {
        "id": "pPgze8X1gmHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = [\"a\", \"b\", \"c\", \"d\"]\n",
        "list2 = [1, 2, 3, 4]"
      ],
      "metadata": {
        "id": "Gq-K8YGXgPW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = spark.sparkContext.parallelize(list(zip(list1,list2)))\n",
        "df = rdd.toDF([\"list1\",\"list2\"])"
      ],
      "metadata": {
        "id": "4VcSK0KVi280"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(zip(list1,list2),[\"list1\",\"list2\"])\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xItB-UlhAIp",
        "outputId": "91d68efb-39b6-4ed5-f70c-9a2628b02da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|list1|list2|\n",
            "+-----+-----+\n",
            "|    a|    1|\n",
            "|    b|    2|\n",
            "|    c|    3|\n",
            "|    d|    4|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 4"
      ],
      "metadata": {
        "id": "dNtsSSaLhOCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_A = [1, 2, 3, 4, 5]\n",
        "list_B = [4, 5, 6, 7, 8]"
      ],
      "metadata": {
        "id": "DGxu8JCAhGrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_A = spark.createDataFrame([(x,) for x in list_A ],[\"Value\"])\n",
        "df_B = spark.createDataFrame([(x,) for x in list_B ],[\"Value\"])\n",
        "\n",
        "result = df_A.join(df_B,on = \"Value\",how=\"left_anti\")\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJpH3R1KhwDA",
        "outputId": "df1360f4-5985-4ca8-cf20-2846da02e41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|Value|\n",
            "+-----+\n",
            "|    1|\n",
            "|    2|\n",
            "|    3|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext\n",
        "\n",
        "rdd_A = sc.parallelize(list_A)\n",
        "rdd_B = sc.parallelize(list_B)\n",
        "\n",
        "result_rdd = rdd_A.subtract(rdd_B)\n",
        "\n",
        "result_rdd = result_rdd.collect()\n",
        "print(result_rdd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Srk29uFAiCqf",
        "outputId": "6e51d776-f78d-4f34-84c9-4795d998ed0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 5"
      ],
      "metadata": {
        "id": "Swie2Gbcj6Nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext\n",
        "\n",
        "rdd_A = sc.parallelize(list_A)\n",
        "rdd_B = sc.parallelize(list_B)\n",
        "\n",
        "result_rdd_A = rdd_A.subtract(rdd_B)\n",
        "result_rdd_B = rdd_B.subtract(rdd_A)\n",
        "\n",
        "result_rdd = result_rdd_A.union(result_rdd_B)\n",
        "\n",
        "print(result_rdd.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSqAkG7sj2nL",
        "outputId": "17e0af2c-a948-4135-b3ac-06f400545170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 8, 6, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 6"
      ],
      "metadata": {
        "id": "99876XGClIT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"A\", 10), (\"B\", 20), (\"C\", 30), (\"D\", 40), (\"E\", 50), (\"F\", 15), (\"G\", 28), (\"H\", 54), (\"I\", 41), (\"J\", 86)]\n",
        "df = spark.createDataFrame(data, [\"Name\", \"Age\"])\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENHPIr_Skx0F",
        "outputId": "bbafb0e2-c216-4f17-9381-a4b4e98e92c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+\n",
            "|Name|Age|\n",
            "+----+---+\n",
            "|   A| 10|\n",
            "|   B| 20|\n",
            "|   C| 30|\n",
            "|   D| 40|\n",
            "|   E| 50|\n",
            "|   F| 15|\n",
            "|   G| 28|\n",
            "|   H| 54|\n",
            "|   I| 41|\n",
            "|   J| 86|\n",
            "+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantile = df.approxQuantile(\"Age\",[0.0,0.25,0.5,0.75,1.0],0.01)\n",
        "print(quantile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HFB6DCflOwR",
        "outputId": "7aa3557a-5078-4873-ed2a-43f5bbde0550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10.0, 20.0, 30.0, 50.0, 86.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 7"
      ],
      "metadata": {
        "id": "37YAanY1mHgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "# Sample data\n",
        "data = [\n",
        "Row(name='John', job='Engineer'),\n",
        "Row(name='John', job='Engineer'),\n",
        "Row(name='Mary', job='Scientist'),\n",
        "Row(name='Bob', job='Engineer'),\n",
        "Row(name='Bob', job='Engineer'),\n",
        "Row(name='Bob', job='Scientist'),\n",
        "Row(name='Sam', job='Doctor'),\n",
        "]\n",
        "\n",
        "# create DataFrame\n",
        "df = spark.createDataFrame(data)\n",
        "\n",
        "# show DataFrame\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAUFEaMRl37o",
        "outputId": "55c83947-5f85-497a-b2fc-102b676da104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+\n",
            "|name|      job|\n",
            "+----+---------+\n",
            "|John| Engineer|\n",
            "|John| Engineer|\n",
            "|Mary|Scientist|\n",
            "| Bob| Engineer|\n",
            "| Bob| Engineer|\n",
            "| Bob|Scientist|\n",
            "| Sam|   Doctor|\n",
            "+----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"job\",\"name\").count().orderBy(\"count\",ascending=False).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0Hd4T3gmMK3",
        "outputId": "8eb2d7e6-203f-4121-b74d-8b2725a966b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+-----+\n",
            "|      job|name|count|\n",
            "+---------+----+-----+\n",
            "| Engineer|John|    2|\n",
            "| Engineer| Bob|    2|\n",
            "|Scientist|Mary|    1|\n",
            "|   Doctor| Sam|    1|\n",
            "|Scientist| Bob|    1|\n",
            "+---------+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 8"
      ],
      "metadata": {
        "id": "NoT6QMnsnfnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "# Sample data\n",
        "data = [\n",
        "Row(name='John', job='Engineer'),\n",
        "Row(name='John', job='Engineer'),\n",
        "Row(name='Mary', job='Scientist'),\n",
        "Row(name='Bob', job='Engineer'),\n",
        "Row(name='Bob', job='Engineer'),\n",
        "Row(name='Bob', job='Scientist'),\n",
        "Row(name='Sam', job='Doctor'),\n",
        "]\n",
        "\n",
        "# create DataFrame\n",
        "df = spark.createDataFrame(data)\n",
        "\n",
        "# show DataFrame\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4sfr7LGmfka",
        "outputId": "345b6485-d023-409e-ff47-b5710e8b0bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+\n",
            "|name|      job|\n",
            "+----+---------+\n",
            "|John| Engineer|\n",
            "|John| Engineer|\n",
            "|Mary|Scientist|\n",
            "| Bob| Engineer|\n",
            "| Bob| Engineer|\n",
            "| Bob|Scientist|\n",
            "| Sam|   Doctor|\n",
            "+----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_top_2 = df.groupBy(\"job\",\"name\").count().orderBy(\"count\",ascending=False).limit(2)\n",
        "df_top_2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBrBsQk0njF9",
        "outputId": "73263ad7-acf6-4e7a-8ec3-e5ad73d644f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+-----+\n",
            "|     job|name|count|\n",
            "+--------+----+-----+\n",
            "|Engineer|John|    2|\n",
            "|Engineer| Bob|    2|\n",
            "+--------+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 10"
      ],
      "metadata": {
        "id": "cnS2l-FwoiTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# suppose you have the following DataFrame\n",
        "df = spark.createDataFrame([(1, 2, 3), (4, 5, 6)], [\"col1\", \"col2\", \"col3\"])\n",
        "\n",
        "# old column names\n",
        "old_names = [\"col1\", \"col2\", \"col3\"]\n",
        "\n",
        "# new column names\n",
        "new_names = [\"new_col1\", \"new_col2\", \"new_col3\"]\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuTJRT5AoBcb",
        "outputId": "a4401566-8e4e-4271-9e3e-3e4fbb8f35cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----+\n",
            "|col1|col2|col3|\n",
            "+----+----+----+\n",
            "|   1|   2|   3|\n",
            "|   4|   5|   6|\n",
            "+----+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for old_name, new_name in zip(old_names, new_names):\n",
        "  df = df.withColumnRenamed(old_name, new_name)\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3UpOPUfor6W",
        "outputId": "692f9cc0-6f9b-48b1-d9c4-28f8e779508c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+--------+\n",
            "|new_col1|new_col2|new_col3|\n",
            "+--------+--------+--------+\n",
            "|       1|       2|       3|\n",
            "|       4|       5|       6|\n",
            "+--------+--------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 13"
      ],
      "metadata": {
        "id": "o7VExXZrp-uV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import rand\n",
        "\n",
        "# Generate a DataFrame with a single column \"id\" with 10 rows\n",
        "df = spark.range(10)\n",
        "\n",
        "# Generate a random float between 0 and 1, scale and shift it to get a random integer between 1 and 10\n",
        "df = df.withColumn(\"random\", ((rand(seed=42) * 10) + 1).cast(\"int\"))\n",
        "\n",
        "# Show the DataFrame\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw8-5m7Gp92C",
        "outputId": "4a8b6f95-c1cb-42e9-b339-b228ad64f7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+\n",
            "| id|random|\n",
            "+---+------+\n",
            "|  0|     7|\n",
            "|  1|     6|\n",
            "|  2|     9|\n",
            "|  3|     3|\n",
            "|  4|     7|\n",
            "|  5|     9|\n",
            "|  6|     7|\n",
            "|  7|     3|\n",
            "|  8|     3|\n",
            "|  9|     7|\n",
            "+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df[\"random\"]% 3 == 0).select(\"id\",\"random\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8iIfjVqq58b",
        "outputId": "e661ccec-1781-4fa3-8a5c-58c2a29c3925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+\n",
            "| id|random|\n",
            "+---+------+\n",
            "|  1|     6|\n",
            "|  2|     9|\n",
            "|  3|     3|\n",
            "|  5|     9|\n",
            "|  7|     3|\n",
            "|  8|     3|\n",
            "+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "df.withColumn(\"Multiple of 3\",when(df[\"random\"]% 3 == 0, 1).otherwise(0)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La7QN5--rLZz",
        "outputId": "0b8f611b-f2d0-4c65-d727-06b7d2c6a8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+-------------+\n",
            "| id|random|Multiple of 3|\n",
            "+---+------+-------------+\n",
            "|  0|     7|            0|\n",
            "|  1|     6|            1|\n",
            "|  2|     9|            1|\n",
            "|  3|     3|            1|\n",
            "|  4|     7|            0|\n",
            "|  5|     9|            1|\n",
            "|  6|     7|            0|\n",
            "|  7|     3|            1|\n",
            "|  8|     3|            1|\n",
            "|  9|     7|            0|\n",
            "+---+------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 14"
      ],
      "metadata": {
        "id": "YNXB04Z9sTkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos = [0,4,8,5]\n",
        "\n",
        "# To create Index\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number\n",
        "\n",
        "window = Window.orderBy(\"id\")\n",
        "df = df.withColumn(\"index\", row_number().over(window) -1)\n",
        "\n",
        "df.filter(df[\"index\"].isin(pos)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uzeHzJJr4hY",
        "outputId": "9663f212-05ca-44c9-e380-c78f6e3313a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+-----+\n",
            "| id|random|index|\n",
            "+---+------+-----+\n",
            "|  0|     7|    0|\n",
            "|  4|     7|    4|\n",
            "|  5|     9|    5|\n",
            "|  8|     3|    8|\n",
            "+---+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 15"
      ],
      "metadata": {
        "id": "N_cmbzvXuTpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame for region A\n",
        "df_A = spark.createDataFrame([(\"apple\", 3, 5), (\"banana\", 1, 10), (\"orange\", 2, 8)], [\"Name\", \"Col_1\", \"Col_2\"])\n",
        "df_A.show()\n",
        "\n",
        "# Create DataFrame for region B\n",
        "df_B = spark.createDataFrame([(\"apple\", 3, 5), (\"banana\", 1, 15), (\"grape\", 4, 6)], [\"Name\", \"Col_1\", \"Col_3\"])\n",
        "df_B.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vgpJ5BVs4x1",
        "outputId": "599b66b3-dfb6-4f91-9839-2988dc9f04cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-----+\n",
            "|  Name|Col_1|Col_2|\n",
            "+------+-----+-----+\n",
            "| apple|    3|    5|\n",
            "|banana|    1|   10|\n",
            "|orange|    2|    8|\n",
            "+------+-----+-----+\n",
            "\n",
            "+------+-----+-----+\n",
            "|  Name|Col_1|Col_3|\n",
            "+------+-----+-----+\n",
            "| apple|    3|    5|\n",
            "|banana|    1|   15|\n",
            "| grape|    4|    6|\n",
            "+------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_A.unionAll(df_B).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf4ZktPLuVU_",
        "outputId": "a9cb51cf-86ce-4794-caa4-75e92338f485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-----+\n",
            "|  Name|Col_1|Col_2|\n",
            "+------+-----+-----+\n",
            "| apple|    3|    5|\n",
            "|banana|    1|   10|\n",
            "|orange|    2|    8|\n",
            "| apple|    3|    5|\n",
            "|banana|    1|   15|\n",
            "| grape|    4|    6|\n",
            "+------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 17"
      ],
      "metadata": {
        "id": "FFrJ7DJkuiee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppose you have the following DataFrame\n",
        "data = [(\"john\",), (\"alice\",), (\"bob\",)]\n",
        "df = spark.createDataFrame(data, [\"name\"])\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvL6kXBBuepO",
        "outputId": "01601de7-fb7f-48eb-bd9c-fbb98490b6e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "| name|\n",
            "+-----+\n",
            "| john|\n",
            "|alice|\n",
            "|  bob|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import initcap\n",
        "\n",
        "df.withColumn(\"name\",initcap(\"name\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGDqA0w2vPAe",
        "outputId": "b5bef556-95c1-4091-e2a5-76786c035b69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "| name|\n",
            "+-----+\n",
            "| John|\n",
            "|Alice|\n",
            "|  Bob|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 18"
      ],
      "metadata": {
        "id": "uRYyyPH1xVGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For the sake of example, we'll create a sample DataFrame\n",
        "data = [('James', 34, 55000),\n",
        "('Michael', 30, 70000),\n",
        "('Robert', 37, 60000),\n",
        "('Maria', 29, 80000),\n",
        "('Jen', 32, 65000)]\n",
        "\n",
        "df = spark.createDataFrame(data, [\"name\", \"age\" , \"salary\"])\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhZm0njAw9EG",
        "outputId": "e23298e3-bc2b-40ae-fbc2-8355db8070e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+------+\n",
            "|   name|age|salary|\n",
            "+-------+---+------+\n",
            "|  James| 34| 55000|\n",
            "|Michael| 30| 70000|\n",
            "| Robert| 37| 60000|\n",
            "|  Maria| 29| 80000|\n",
            "|    Jen| 32| 65000|\n",
            "+-------+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.summary().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P0P-_iCxTra",
        "outputId": "08c92a3b-d60e-4764-da53-705fc20c8142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+-----------------+-----------------+\n",
            "|summary|  name|              age|           salary|\n",
            "+-------+------+-----------------+-----------------+\n",
            "|  count|     5|                5|                5|\n",
            "|   mean|  NULL|             32.4|          66000.0|\n",
            "| stddev|  NULL|3.209361307176242|9617.692030835671|\n",
            "|    min| James|               29|            55000|\n",
            "|    25%|  NULL|               30|            60000|\n",
            "|    50%|  NULL|               32|            65000|\n",
            "|    75%|  NULL|               34|            70000|\n",
            "|    max|Robert|               37|            80000|\n",
            "+-------+------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxZ-2OGzxZdq",
        "outputId": "b8c2bb76-1d5d-4cb0-b199-e6df0598993f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+-----------------+-----------------+\n",
            "|summary|  name|              age|           salary|\n",
            "+-------+------+-----------------+-----------------+\n",
            "|  count|     5|                5|                5|\n",
            "|   mean|  NULL|             32.4|          66000.0|\n",
            "| stddev|  NULL|3.209361307176242|9617.692030835671|\n",
            "|    min| James|               29|            55000|\n",
            "|    max|Robert|               37|            80000|\n",
            "+-------+------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 19"
      ],
      "metadata": {
        "id": "52mU_CVJxh3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"john\",), (\"alice\",), (\"bob\",)]\n",
        "df = spark.createDataFrame(data, [\"name\"])\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8VPHZidxcuS",
        "outputId": "2bdbbfa1-c595-495f-b2b2-349e2aab8dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "| name|\n",
            "+-----+\n",
            "| john|\n",
            "|alice|\n",
            "|  bob|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import char_length\n",
        "df = df.withColumn(\"character_present\", char_length(\"name\")).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kglGvKkWxkl_",
        "outputId": "868f17e1-adbc-48d9-9da5-7d5868c9a7b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+\n",
            "| name|character_present|\n",
            "+-----+-----------------+\n",
            "| john|                4|\n",
            "|alice|                5|\n",
            "|  bob|                3|\n",
            "+-----+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) 20"
      ],
      "metadata": {
        "id": "N3B3mu6xyFL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.max(\"character_present\").show()"
      ],
      "metadata": {
        "id": "u3szw4kwx7QI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "54670c56-88b6-4da2-be64-549262b87129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'max'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-b4ee99ff5fd0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"character_present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'max'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is from video: https://www.youtube.com/watch?v=cu0iQ96XMtc&list=PLxHEfsUVhEwMvQBr10rrpEsnwT3AXBKke&index=3&ab_channel=CloudChallengers"
      ],
      "metadata": {
        "id": "VmNRyVDN4RA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"questions\").getOrCreate()"
      ],
      "metadata": {
        "id": "3CTqih4HICyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(\n",
        "    [\n",
        "        (\"John,Doe\",\"Canada\"),\n",
        "        (\"Mike,David\",\"USA\")\n",
        "    ], [\"Name\",\"Country\"]\n",
        ")\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ga8Qjeug4nJT",
        "outputId": "8409d856-1e4d-47da-832e-a87418a4d370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+\n",
            "|      Name|Country|\n",
            "+----------+-------+\n",
            "|  John,Doe| Canada|\n",
            "|Mike,David|    USA|\n",
            "+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "df.withColumn(\"Name\",F.explode(F.split(\"Name\",\",\"))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylC7lzf15HVm",
        "outputId": "e876f8db-29fb-492e-b069-ef0b1f3a9483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+\n",
            "| Name|Country|\n",
            "+-----+-------+\n",
            "| John| Canada|\n",
            "|  Doe| Canada|\n",
            "| Mike|    USA|\n",
            "|David|    USA|\n",
            "+-----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType"
      ],
      "metadata": {
        "id": "RgURWlNB5ego"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType([\n",
        "    StructField(\"player\", StringType(), True),\n",
        "    StructField(\"runs\", IntegerType(), True),\n",
        "    StructField(\"50s/100s\", StringType(), True)\n",
        "])\n"
      ],
      "metadata": {
        "id": "4LsuC_Qg7P32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"Sachin-IND\", 18694, \"93/49\"), (\"Ricky-AUS\", 11274, \"66/31\"),(\"Lara-WI\", 10222, \"45/21\"),(\"Rahul-IND\", 10355, \"95/11\"),(\"Jhonty-SA\", 7051, \"43/5\"),(\"Hayden-AUS\", 8722, \"67/19\")]\n",
        "players_df = spark.createDataFrame(data, schema)"
      ],
      "metadata": {
        "id": "PZjPAgn77RV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = [(\"IND\", \"India\"), (\"AUS\", \"Australia\"), (\"WI\", \"WestIndies\"), (\"SA\", \"SouthAfrica\")]\n",
        "countries_df = spark.createDataFrame(data1,[\"SRT\",\"country\"])\n"
      ],
      "metadata": {
        "id": "tm_1aCpc7S7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q) 2"
      ],
      "metadata": {
        "id": "2wvhTX1E_aqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "players_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_10pJcY7UdP",
        "outputId": "ef31752b-1219-4016-d132-3b2f7b72f10b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+--------+\n",
            "|    player| runs|50s/100s|\n",
            "+----------+-----+--------+\n",
            "|Sachin-IND|18694|   93/49|\n",
            "| Ricky-AUS|11274|   66/31|\n",
            "|   Lara-WI|10222|   45/21|\n",
            "| Rahul-IND|10355|   95/11|\n",
            "| Jhonty-SA| 7051|    43/5|\n",
            "|Hayden-AUS| 8722|   67/19|\n",
            "+----------+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "countries_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9pD9kUP7WLo",
        "outputId": "4a6ec11a-0729-410d-cf82-74c332a38a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------+\n",
            "|SRT|    country|\n",
            "+---+-----------+\n",
            "|IND|      India|\n",
            "|AUS|  Australia|\n",
            "| WI| WestIndies|\n",
            "| SA|SouthAfrica|\n",
            "+---+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "players_df = players_df.withColumn(\"50s\",F.split(\"50s/100s\",\"/\").getItem(0).cast(\"int\"))\\\n",
        "          .withColumn(\"100s\",F.split(\"50s/100s\",\"/\").getItem(1).cast(\"int\"))"
      ],
      "metadata": {
        "id": "hjqLhGoM7aZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "players_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETOlaDEd9oiP",
        "outputId": "42b9617a-7228-4fae-881e-8e6ecec6cdc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+--------+---+----+\n",
            "|    player| runs|50s/100s|50s|100s|\n",
            "+----------+-----+--------+---+----+\n",
            "|Sachin-IND|18694|   93/49| 93|  49|\n",
            "| Ricky-AUS|11274|   66/31| 66|  31|\n",
            "|   Lara-WI|10222|   45/21| 45|  21|\n",
            "| Rahul-IND|10355|   95/11| 95|  11|\n",
            "| Jhonty-SA| 7051|    43/5| 43|   5|\n",
            "|Hayden-AUS| 8722|   67/19| 67|  19|\n",
            "+----------+-----+--------+---+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "players_df = players_df.withColumn(\"sum\", F.col(\"50s\")+F.col(\"100s\"))"
      ],
      "metadata": {
        "id": "vz2j1Laj8eKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "players_df = players_df.withColumn(\"playername\",F.split(\"player\",\"-\").getItem(0).cast(\"string\"))\\\n",
        ".withColumn(\"SRT\",F.split(\"player\",\"-\").getItem(1).cast(\"string\"))\n",
        "\n",
        "players_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY5C9yVS9m6x",
        "outputId": "abcdac0e-9887-451f-aeff-646e5cd04066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+--------+---+----+---+----------+-------+---+\n",
            "|    player| runs|50s/100s|50s|100s|sum|playername|country|SRT|\n",
            "+----------+-----+--------+---+----+---+----------+-------+---+\n",
            "|Sachin-IND|18694|   93/49| 93|  49|142|    Sachin|    IND|IND|\n",
            "| Ricky-AUS|11274|   66/31| 66|  31| 97|     Ricky|    AUS|AUS|\n",
            "|   Lara-WI|10222|   45/21| 45|  21| 66|      Lara|     WI| WI|\n",
            "| Rahul-IND|10355|   95/11| 95|  11|106|     Rahul|    IND|IND|\n",
            "| Jhonty-SA| 7051|    43/5| 43|   5| 48|    Jhonty|     SA| SA|\n",
            "|Hayden-AUS| 8722|   67/19| 67|  19| 86|    Hayden|    AUS|AUS|\n",
            "+----------+-----+--------+---+----+---+----------+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "players_df.join(countries_df, on = \"SRT\",how=\"left\").filter(players_df[\"sum\"] > 90).select(\"playername\",countries_df[\"country\"],\"runs\",\"sum\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-h9G8d0-ZJu",
        "outputId": "ad865b07-3a7f-4dc9-c630-caf9c65072ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+-----+---+\n",
            "|playername|  country| runs|sum|\n",
            "+----------+---------+-----+---+\n",
            "|     Ricky|Australia|11274| 97|\n",
            "|    Sachin|    India|18694|142|\n",
            "|     Rahul|    India|10355|106|\n",
            "+----------+---------+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q) 4"
      ],
      "metadata": {
        "id": "fSO4mPyY_d6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list = [(101,'prod1',1200,'Bangalore'),(102,'prod2',1050,'Bangalore'),(103,'prod3',900,'Mysore'),(104,'prod4',950, 'Mysore')]\n",
        "header = ['pid','name','sales','region']\n",
        "df3 = spark.createDataFrame(list,header)\n",
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ar_DtvD-_P_o",
        "outputId": "fcc4c526-0449-4cfc-82ee-066455b50634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+-----+---------+\n",
            "|pid| name|sales|   region|\n",
            "+---+-----+-----+---------+\n",
            "|101|prod1| 1200|Bangalore|\n",
            "|102|prod2| 1050|Bangalore|\n",
            "|103|prod3|  900|   Mysore|\n",
            "|104|prod4|  950|   Mysore|\n",
            "+---+-----+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "\n",
        "win_spec = Window.partitionBy(\"region\")\n",
        "\n",
        "df3.withColumn(\"Sum_by_region\", F.sum(\"sales\").over(win_spec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk7p2tjgA89a",
        "outputId": "bd90686b-5760-43a1-c365-4dda251c8db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+-----+---------+-------------+\n",
            "|pid| name|sales|   region|Sum_by_region|\n",
            "+---+-----+-----+---------+-------------+\n",
            "|101|prod1| 1200|Bangalore|         2250|\n",
            "|102|prod2| 1050|Bangalore|         2250|\n",
            "|103|prod3|  900|   Mysore|         1850|\n",
            "|104|prod4|  950|   Mysore|         1850|\n",
            "+---+-----+-----+---------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q) 5"
      ],
      "metadata": {
        "id": "MdTzunO4BkE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType([\n",
        "    StructField(\"reqid\", IntegerType(), True),\n",
        "    StructField(\"pickup_location\", StringType(), True)\n",
        "])"
      ],
      "metadata": {
        "id": "2gscqkLuBefW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(48, \"Airport\"), (49, \"Office\"),(50, \"Hospital\"),(51, \"Airport\"),(52, \"Hospital\"),(53, \"Shoppingmall\"),(54, \"Office\"),(55, \"Hospital\"),(56, \"Hospital\")]\n",
        "pickup_df = spark.createDataFrame(data, schema)\n",
        "pickup_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wEs61nIBrxG",
        "outputId": "9c71cce1-f35d-42ee-bfaa-459ccdd9e38f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------------+\n",
            "|reqid|pickup_location|\n",
            "+-----+---------------+\n",
            "|   48|        Airport|\n",
            "|   49|         Office|\n",
            "|   50|       Hospital|\n",
            "|   51|        Airport|\n",
            "|   52|       Hospital|\n",
            "|   53|   Shoppingmall|\n",
            "|   54|         Office|\n",
            "|   55|       Hospital|\n",
            "|   56|       Hospital|\n",
            "+-----+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickup_df.groupBy(\"pickup_location\").agg(F.count(\"*\").alias(\"frequency\")).orderBy(\"frequency\", ascending = False).limit(3).select(\"pickup_location\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8amxu7CBt9B",
        "outputId": "ea12fc5f-4ab4-4067-d827-cc3122d135c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|pickup_location|\n",
            "+---------------+\n",
            "|       Hospital|\n",
            "|         Office|\n",
            "|        Airport|\n",
            "+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q) 6"
      ],
      "metadata": {
        "id": "69uXNuvxC2yP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (100, 'IT', 100, '2024-05-12'),\n",
        "    (200, 'IT', 100, '2024-06-12'),\n",
        "    (100, 'FIN', 400, '2024-07-12'),\n",
        "    (300, 'FIN', 500, '2024-07-12'),\n",
        "    (300, 'FIN', 1543, '2024-07-12'),\n",
        "    (300, 'FIN', 1500, '2024-07-12')\n",
        "]\n",
        "\n",
        "columns = [\"empid\", \"dept\", \"salary\", \"date\"]\n",
        "df = spark.createDataFrame(data, columns)"
      ],
      "metadata": {
        "id": "lGLmzzfCCmCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "empid_counts = df.groupBy(\"empid\").agg(F.count(\"empid\").alias(\"freq_id\"))\n",
        "\n",
        "empid_counts.join(df,on=\"empid\",how=\"left\").filter(F.col(\"freq_id\") == 1).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nCU-SGLDBYT",
        "outputId": "53307d21-ebfa-4c9a-c364-b321eee07603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+----+------+----------+\n",
            "|empid|freq_id|dept|salary|      date|\n",
            "+-----+-------+----+------+----------+\n",
            "|  200|      1|  IT|   100|2024-06-12|\n",
            "+-----+-------+----+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6XypLhg5D8ue"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}